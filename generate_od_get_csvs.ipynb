{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate Origin Destination Cost Matrix\n",
    "Description: Find and measure the least-cost paths along the network from multiple origins to multiple destinations.\n",
    "## Setup Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import arcpy\n",
    "from arcpy import env\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "arcpy.CheckOutExtension('Network')\n",
    "arcpy.CheckOutExtension(\"Highways\")\n",
    "\n",
    "env.workspace = \"C:\\data\" # directory with your \"large roads speeds\" and \"tracts centroids\" subdirectories\n",
    "env.overwriteOutput = True\n",
    "\n",
    "centroid_folder = 'tracts centroids' #relative path from env.workspace path\n",
    "network_dataset_shp = 'large roads speeds\\large_roads_speeds.shp' #relative path from env.workspace path\n",
    "network_dataset_nd = 'large roads speeds\\large_roads_speeds_ND.nd' #relative path from env.workspace path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_network_dataset_shp_indices(network_dataset_shp):\n",
    "    '''\n",
    "    Return True if Network Dataset has the spatial and attribute Indices added\n",
    "    '''\n",
    "    #helper functions\n",
    "    def check_2_fields(fields):\n",
    "        if len(fields) != 2:\n",
    "            return False\n",
    "        for field in fields:\n",
    "            if len(field) != 1:\n",
    "                return False\n",
    "    def extract(fields):\n",
    "        return [fields[0][0], fields[1][0]]\n",
    "    indexes = arcpy.ListIndexes(network_dataset_shp)\n",
    "    fields =  [index.fields for index in indexes]\n",
    "    def check_fields(spatial_field, attribute_field):\n",
    "        if spatial_field.name == \"Shape\" and spatial_field.type == \"Geometry\":\n",
    "            if attribute_field.name == \"seconds\" and attribute_field.type == \"Double\":\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    #check index fields are the correct format\n",
    "    if check_2_fields(fields) == False:\n",
    "        return False\n",
    "    fields = extract(fields)\n",
    "    return check_fields(fields[0], fields[1]) or check_fields(fields[1], fields[0])\n",
    "\n",
    "def verify_centroid_indices(centroid):\n",
    "    '''\n",
    "    Return True if centroid has the spatial Index added\n",
    "    '''\n",
    "    indexes = arcpy.ListIndexes(centroid)\n",
    "    if len(indexes) != 1:\n",
    "        return False\n",
    "    field = indexes[0].fields[0]\n",
    "    return field.name == \"Shape\" and field.type == \"Geometry\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def index_setup(network_dataset_shp, centroid):\n",
    "    if not verify_network_dataset_shp_indices(network_dataset_shp):\n",
    "        #ND seconds atribute spatial index\n",
    "        arcpy.AddIndex_management(network_dataset_shp, \"seconds\")\n",
    "        #ND spatial index\n",
    "        arcpy.AddSpatialIndex_management(network_dataset_shp, \"\")\n",
    "        assert(verify_network_dataset_shp_indices(network_dataset_shp))\n",
    "    print(\"indexes successfully set for network dataset\")\n",
    "    if not verify_centroid_indices(centroid):\n",
    "        #centroid spatial index\n",
    "        arcpy.AddSpatialIndex_management(centroid, \"\")\n",
    "        assert(verify_centroid_indices(centroid))\n",
    "    print(\"indexes successfully set for centroid\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_od_inputs(centroid, centroid_directory, network_dataset_nd):\n",
    "    #Origins setup\n",
    "    inOrigins = centroid\n",
    "    inDestinations = inOrigins\n",
    "    #Network Dataset setup\n",
    "    inNetworkDataset = network_dataset_nd\n",
    "    #Output setup\n",
    "    out_folder_path = centroid_directory\n",
    "    out_name = \"od_output.gdb\"\n",
    "    arcpy.CreateFileGDB_management(out_folder_path, out_name)\n",
    "    outGeodatabase = os.path.join(out_folder_path, out_name)\n",
    "    return inOrigins, inDestinations, inNetworkDataset, outGeodatabase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate OD Matrix in geodatabase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_od_matrix(inOrigins, inDestinations, inNetworkDataset, outGeodatabase):\n",
    "    arcpy.na.GenerateOriginDestinationCostMatrix(inOrigins, inDestinations, inNetworkDataset, outGeodatabase,\n",
    "                                                  Origin_Destination_Line_Shape='NO_LINES', Save_Output_Network_Analysis_Layer = \"NO_SAVE_OUTPUT_LAYER\",\n",
    "                                                Maximum_Snap_Tolerance = 25000)\n",
    "    #\"NO_LINES\" boosts performance\n",
    "    #the output is stored in output.gdb so we don't need the network_analysis_layer.\n",
    "    print 'completed od matrix successfully'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert OD Matrix From Geodatabase to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_csv(centroid_directory, outGeodatabase):\n",
    "    inTable = os.path.join(outGeodatabase, \"ODLines\")\n",
    "    outLocation = centroid_directory\n",
    "    outTable = \"od_output.csv\"\n",
    "    arcpy.TableToTable_conversion(inTable, outLocation, outTable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Find Centroid Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def find_centroid(centroid_folder):\n",
    "    for directory, _, files in os.walk(os.path.join(env.workspace, centroid_folder)):\n",
    "        for file in files:\n",
    "            if \".shp\" == file[-4:]:\n",
    "                centroid_directory = directory\n",
    "                centroid_shp = os.path.join(directory, file)\n",
    "                yield centroid_directory, centroid_shp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_centroids: 5\n"
     ]
    }
   ],
   "source": [
    "def calculate_total_centroids():\n",
    "    total_centroids = 0\n",
    "    for _, _ in find_centroid(centroid_folder):\n",
    "        total_centroids+=1\n",
    "    print 'total_centroids: ' + str(total_centroids)\n",
    "    return total_centroids\n",
    "total_centroids = calculate_total_centroids()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for centroid_directory, centroid_shp in find_centroid(centroid_folder):\n",
    "    index_setup(network_dataset_shp, centroid_shp)\n",
    "    inOrigins, inDestinations, inNetworkDataset, outGeodatabase = setup_od_inputs(centroid_shp, centroid_directory, network_dataset_nd)\n",
    "    generate_od_matrix(inOrigins, inDestinations, inNetworkDataset, outGeodatabase) # 16 minutes\n",
    "    output_csv(centroid_directory, outGeodatabase) # 2 minutes\n",
    "    count+=1\n",
    "    print \"completed\" + str(count) + \"out of \" + str(total_centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for centroid_directory, centroid_shp in find_centroid(centroid_folder):\n",
    "    print centroid_shp\n",
    "    inTable = arcpy.SearchCursor(centroid_shp)\n",
    "    outLocation = centroid_directory\n",
    "    outTable = \"centroid.csv\"\n",
    "    arcpy.TableToTable_conversion(inTable, outLocation, outTable)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make New OD Matrix With Origin and Destination Census IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_centroids_with_od_output(centroid_folder):\n",
    "    for directory, _, files in os.walk(os.path.join(env.workspace, centroid_folder)):\n",
    "        for file in files:\n",
    "            if \"od_output.csv\" in files:\n",
    "                if \".shp\" == file[-4:]:\n",
    "                    centroid_directory = directory\n",
    "                    centroid_shp = os.path.join(directory, file)\n",
    "                    yield centroid_directory, centroid_shp\n",
    "def count_total():\n",
    "    count = 0\n",
    "    for each,_ in find_centroids_with_od_output(centroid_folder):\n",
    "        count += 1\n",
    "    return count\n",
    "\n",
    "def add_census_id_to_od_matrix(centroid_folder):\n",
    "    total = str(count_total())\n",
    "    print(\"There are \" + total + \" matrices to update\")\n",
    "    count = 0\n",
    "    for centroid_directory, centroid_shp in find_centroids_with_od_output(centroid_folder):\n",
    "        output_df = pd.read_csv(os.path.join(centroid_directory, \"od_output.csv\"))\n",
    "        rows=arcpy.SearchCursor(centroid_shp)\n",
    "        ids = []\n",
    "        #retrieve all the census IDs\n",
    "        for row in rows:\n",
    "            OID = row.getValue(\"FID\")\n",
    "            census_id=row.getValue(\"geo2010\")\n",
    "            ids.append([OID, census_id])\n",
    "        centroid_df =  pd.DataFrame(data=ids, columns = [\"OID\",\"census_id\"])\n",
    "        #create origin and destination matrix to merge with output\n",
    "        origins = centroid_df.rename(columns={\"census_id\":\"census_origin\", \"OID\":\"OriginOID\"}).astype(\"int64\")\n",
    "        destinations = centroid_df.rename(columns={\"census_id\":\"census_destination\", \"OID\":\"DestinationOID\"}).astype(\"int64\")\n",
    "        #merge origin and destination census_ids with OD_matrix\n",
    "        result = output_df.merge(origins, how=\"left\").merge(destinations, how=\"left\")\n",
    "        #store new csv\n",
    "        output_file = os.path.join(centroid_directory, \"OD_matrix.csv\")\n",
    "        output_columns = [\"Total_Time\", \"Total_Distance\", \"OriginOID\", \"DestinationOID\", \"census_origin\", \"census_destination\"]\n",
    "        result[output_columns].to_csv(output_file)\n",
    "        count+= 1\n",
    "        print(str(count) + \"/\" + total + \" complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_census_id_to_od_matrix(centroid_folder)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
